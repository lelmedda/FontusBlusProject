# conda update scikit-learn
import numpy as np
import pandas as pd 
from matplotlib import pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split

data = pd.read_excel("FontusBlue Data.xlsx",header=[1])
data.head()

data=data.drop(columns=['date','Unnamed: 0'])

#Handle the missing values
print('Number of instances = %d' % (data.shape[0]))
print('Number of attributes = %d' % (data.shape[1]))

print('Number of missing values:')
for col in data.columns:
    print('\t%s: %d' % (col,data[col].isna().sum()))



print('Number of rows before discarding missing values = %d' % (data.shape[0]))
data=data.dropna()
print('Number of rows before discarding missing values = %d' % (data.shape[0]))


df_x=data.iloc[2:35,2:]
df_y=data.iloc[36,2:]

x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=4)

nn=MLPClassifier(activation='logistic',solver='sgd',hidden_layer_sizes=(10,15),random_state=1)

nn.fit(x_train,y_train)


pred=nn.predict(x_test)
#activation logistic with hidden layer sizes-> 45,90 Gave 92 % accuracy
#activation relu with hidden layer sizes-> 45,90 gave 89 % accuracy 
#Test with different combinatations of learning rate, activation and other hyper parameters and mesure the accuracy

a=y_test.values

a
count=0
#In [22]:
for i in range(len(pred)):
    if pred[i]==a[i]:
        count=count+1
